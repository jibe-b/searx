8d335dbd (a01200356   2016-03-14 00:32:36 -0600   1) """
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   2)  Wikipedia (Web)
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   3) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   4)  @website     https://{language}.wikipedia.org
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   5)  @provide-api yes
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   6) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   7)  @using-api   yes
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   8)  @results     JSON
8d335dbd (a01200356   2016-03-14 00:32:36 -0600   9)  @stable      yes
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  10)  @parse       url, infobox
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  11) """
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  12) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  13) from json import loads
f62ce21f (marc        2016-11-05 20:51:38 -0600  14) from lxml.html import fromstring
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  15) from searx.url_utils import quote, urlencode
149802c5 (marc        2016-08-05 23:34:56 -0500  16) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  17) # search-url
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  18) base_url = u'https://{language}.wikipedia.org/'
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  19) search_url = base_url + u'w/api.php?'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  20)     'action=query'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  21)     '&format=json'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  22)     '&{query}'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  23)     '&prop=extracts|pageimages'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  24)     '&exintro'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  25)     '&explaintext'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  26)     '&pithumbsize=300'\
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  27)     '&redirects'
f62ce21f (marc        2016-11-05 20:51:38 -0600  28) supported_languages_url = 'https://meta.wikimedia.org/wiki/List_of_Wikipedias'
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  29) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  30) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  31) # set language in base_url
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  32) def url_lang(lang):
149802c5 (marc        2016-08-05 23:34:56 -0500  33)     lang = lang.split('-')[0]
4d177039 (marc        2017-07-20 15:47:20 -0500  34)     if lang not in supported_languages:
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  35)         language = 'en'
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  36)     else:
149802c5 (marc        2016-08-05 23:34:56 -0500  37)         language = lang
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  38) 
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  39)     return language
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  40) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  41) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  42) # do search-request
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  43) def request(query, params):
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  44)     if query.islower():
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  45)         query = u'{0}|{1}'.format(query.decode('utf-8'), query.decode('utf-8').title()).encode('utf-8')
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  46) 
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  47)     params['url'] = search_url.format(query=urlencode({'titles': query}),
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  48)                                       language=url_lang(params['language']))
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  49) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  50)     return params
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  51) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  52) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  53) # get first meaningful paragraph
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  54) # this should filter out disambiguation pages and notes above first paragraph
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  55) # "magic numbers" were obtained by fine tuning
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  56) def extract_first_paragraph(content, title, image):
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  57)     first_paragraph = None
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  58) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  59)     failed_attempts = 0
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  60)     for paragraph in content.split('\n'):
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  61) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  62)         starts_with_title = paragraph.lower().find(title.lower(), 0, len(title) + 35)
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  63)         length = len(paragraph)
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  64) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  65)         if length >= 200 or (starts_with_title >= 0 and (image or length >= 150)):
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  66)             first_paragraph = paragraph
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  67)             break
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  68) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  69)         failed_attempts += 1
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  70)         if failed_attempts > 3:
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  71)             return None
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  72) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  73)     return first_paragraph
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  74) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  75) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  76) # get response from search-request
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  77) def response(resp):
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  78)     results = []
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  79) 
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100  80)     search_result = loads(resp.text)
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  81) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  82)     # wikipedia article's unique id
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  83)     # first valid id is assumed to be the requested article
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  84)     for article_id in search_result['query']['pages']:
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  85)         page = search_result['query']['pages'][article_id]
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  86)         if int(article_id) > 0:
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  87)             break
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  88) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  89)     if int(article_id) < 0:
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  90)         return []
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  91) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  92)     title = page.get('title')
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  93) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  94)     image = page.get('thumbnail')
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  95)     if image:
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  96)         image = image.get('source')
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  97) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  98)     extract = page.get('extract')
8d335dbd (a01200356   2016-03-14 00:32:36 -0600  99) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 100)     summary = extract_first_paragraph(extract, title, image)
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 101) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 102)     # link to wikipedia article
52e615de (Adam Tauber 2016-11-30 18:43:03 +0100 103)     wikipedia_link = base_url.format(language=url_lang(resp.search_params['language'])) \
c2e40142 (marc        2016-06-24 00:38:17 -0500 104)         + 'wiki/' + quote(title.replace(' ', '_').encode('utf8'))
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 105) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 106)     results.append({'url': wikipedia_link, 'title': title})
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 107) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 108)     results.append({'infobox': title,
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 109)                     'id': wikipedia_link,
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 110)                     'content': summary,
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 111)                     'img_src': image,
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 112)                     'urls': [{'title': 'Wikipedia', 'url': wikipedia_link}]})
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 113) 
8d335dbd (a01200356   2016-03-14 00:32:36 -0600 114)     return results
f62ce21f (marc        2016-11-05 20:51:38 -0600 115) 
f62ce21f (marc        2016-11-05 20:51:38 -0600 116) 
f62ce21f (marc        2016-11-05 20:51:38 -0600 117) # get supported languages from their site
af35eee1 (marc        2016-12-15 00:34:43 -0600 118) def _fetch_supported_languages(resp):
f62ce21f (marc        2016-11-05 20:51:38 -0600 119)     supported_languages = {}
af35eee1 (marc        2016-12-15 00:34:43 -0600 120)     dom = fromstring(resp.text)
f62ce21f (marc        2016-11-05 20:51:38 -0600 121)     tables = dom.xpath('//table[contains(@class,"sortable")]')
f62ce21f (marc        2016-11-05 20:51:38 -0600 122)     for table in tables:
f62ce21f (marc        2016-11-05 20:51:38 -0600 123)         # exclude header row
f62ce21f (marc        2016-11-05 20:51:38 -0600 124)         trs = table.xpath('.//tr')[1:]
f62ce21f (marc        2016-11-05 20:51:38 -0600 125)         for tr in trs:
f62ce21f (marc        2016-11-05 20:51:38 -0600 126)             td = tr.xpath('./td')
f62ce21f (marc        2016-11-05 20:51:38 -0600 127)             code = td[3].xpath('./a')[0].text
f62ce21f (marc        2016-11-05 20:51:38 -0600 128)             name = td[2].xpath('./a')[0].text
f62ce21f (marc        2016-11-05 20:51:38 -0600 129)             english_name = td[1].xpath('./a')[0].text
f62ce21f (marc        2016-11-05 20:51:38 -0600 130)             articles = int(td[4].xpath('./a/b')[0].text.replace(',', ''))
4a1ff563 (marc        2016-12-16 22:14:14 -0600 131)             # exclude languages with too few articles
1175b390 (marc        2016-12-28 23:24:56 -0600 132)             if articles >= 100:
f62ce21f (marc        2016-11-05 20:51:38 -0600 133)                 supported_languages[code] = {"name": name, "english_name": english_name, "articles": articles}
f62ce21f (marc        2016-11-05 20:51:38 -0600 134) 
f62ce21f (marc        2016-11-05 20:51:38 -0600 135)     return supported_languages
